%\documentclass[hidelinks]{report}
%\input{commands.tex}
%
%\begin{document}

\chapter{Experimental Results}

In this chapter, we will present and analyse the results of the experiments conducted for this thesis. The chapter consists of 5 sections.

In the first section, we will give a description of the different corpora we had available and used for our experiment. In Section \ref{sec:exp1}, we will present the results for our first experiment, in which we measured the consistency of the corpus according to consistency Definition \ref{def:depHAT}, and shortly explain how they are to be interpreted. We will proceed similarly in Section \ref{sec:exp2}, where we will present the results for our second experiment, in which we measured the consistency of the corpus according to the second definition of consistency, taking into account flatter forms of compositionality. In Section \ref{sec:man}, we will analyse the reasons for inconsistency between dependency parses and HATs. Lastly, we will describe the follow-up experiments that we have conducted to test if using dependency parses to find a compositional grammar for the data seems within reach in Section \ref{sec:stat}.


\section{Data}
\label{sec:data}

We had available 4 large automatically aligned parallel corpora for the language pairs English-Dutch, English-French, English-German and English-Chinese. The first thee corpora were data from the European Parliament taken from the Europarl corpus \citep{koehn2005europarl}, while the English-Chinese data came from the Hong Kong Parallel Corpus. The word-alignments were found using GIZA++ \citep{och03:asc}, using the previously mentioned `grow-diag-and-final'-heuristic, with 4 iterations on model 1, and 3 iterations with the hmm model, model 3 and model 4. The corpora were tokenised and lowercased before GIZA++ was run. In general, the guidelines for building a baseline for the WMT workshops were followed.\footnote{See http://www.statmt.org/wmt07/baseline.html}

In addition to the automatically aligned corpora, we had access to 5 manually aligned corpora. These corpora were much smaller than the automatically aligned corpora, and covered the language pairs English-French \citep{graca2008building,och2000improved}, English-Spanish, English-Portuguese \citep{graca2008building}, English-German \citep{pado2006optimal}.

\begin{table}[!ht]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\bf Language pair & \bf Source & \bf Size & \bf Alignments\\
\hline \hline
English - Dutch & European Parliament & 945167 & {\small GIZA++} \\
\hline
English - German & European Parliament & 995909 & {\small GIZA++} \\
& Europarl & 987 & {\small\cite{pado2006optimal}}\\
\hline
English - Chinese & Hong Kong Parallel Corpus & 1723487 & {\small GIZA++} \\
\hline
English - French & European Parliament & 949408 & {\small GIZA++} \\
& Hansard & 447 & {\small \cite{och2000improved}}\\
& Europarl & 100 & {\small \cite{graca2008building}} \\
\hline
English - Spanish & Europarl & 100 & {\small \cite{graca2008building}} \\
\hline
English - Portuguese & Europarl & 100 & {\small \cite{graca2008building}}\\
\hline
\end{tabular}
\caption{Datasets}\label{tab:datasets}
\end{table}

\section{Experiment part 1}
\label{sec:exp1}

In our first experiment, we measured the consistency of dependency parses and HAT through consistency definition \ref{def:depHAT}. According to this definition, a dependency relation is preserved in a HAT if the head and the phrase headed by the dependent are siblings in the HAT. We ran the experiment on the first 10.000 sentences of our automatically aligned datasets and on all manually aligned datasets. The consistency scores for automatic and manual alignments can be found in Table \ref{tab:scores1} and \ref{tab:scores2}, respectively. We reported on the scores for sentences shorter than 10, 20 and 40 words.

%maybe change numbers to numbers of larger datasets later
\begin{table}[!ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
&\multicolumn{3}{c|}{\textbf{Similarity Score}}\\
\textbf{Language Pair} & |s| < 10 & |s| < 20 & |s| < 40\\
\hline \hline
English-Dutch & 0.47 & 0.42 & 0.40 \\
\hline
English-French & 0.46 & 0.42 & 041 \\
\hline
English-German & 0.44 & 0.41 & 0.38 \\
\hline
English-Chinese & 0.59 & 0.48 & 0.42\\
\hline
\end{tabular}
\caption{Consistency scores of automatically aligned corpora according to consistency definition \ref{def:depHAT}.}\label{tab:scores1}
\end{table}

\begin{table}[!ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
&\multicolumn{3}{c|}{\textbf{Similarity Score}}\\
\textbf{Language Pair} & |s| < 10 & |s| < 20 & |s| < 40\\
\hline \hline
English-French (Hansard) & 0.63 & 0.54 & 0.51 \\
\hline
English-French (LREC) & 0.49 & 0.47 & 0.47 \\
\hline
English-German (Pado) & 0.43 & 0.42 & 0.41 \\
\hline
English-Portuguese (LREC) & 0.47 & 0.45 & 0.45 \\
\hline
English- Spanish (LREC) & 0.51 & 0.48 & 0.48\\
\hline
\end{tabular}
\caption{Consistency scores of manually aligned corpora according to consistency definition \ref{def:depHAT}}\label{tab:scores2}
\end{table}

The direct consistency scores are very low, on average not even half of the dependency relations of the English sentence are respected by any HAT. The dependency relations of shorter sentences are generally better respected than the dependency relations of longer sentences. The difference between the scores of the automatically aligned datasets and the manually aligned datasets is lower than we expected, which could indicate the influence of mistakes in the automatically aligned datasets is relatively small. However, the large difference between the two manually aligned French datasets indicates that is more likely due to the fact that the manually aligned datasets are too small to get a significant result.

\begin{table}[!ht]
\centering
\begin{tabular}{|l|c|c|}
\hline\textbf{Language Pair} & \textbf{Dependency} &\textbf{best HAT}\\
\hline \hline
English-Dutch & 3.1 & 2.1 \\
\hline
English-French & 3.1 & 2.1 \\
\hline
English-German & 3.1 & 2.11 \\
\hline
English-Chinese & 3.0 & 2.2\\
\hline
\end{tabular}
\caption{Average branching factors}\label{tab:branching}
\end{table}

From this single experiment it is unclear whether the low scores indicate that dependency parses cannot be used bilingually, or should be attributed to the fact that their type of compositionality is not maximally recursive. A short study of the branching factors of the nodes in the dependency parses and the selected HATs suggests that the latter played indeed a role. Figure \ref{fig:branching} we can see that the branching factor in the compositional structures prescribed by dependency parses is much higher than the branching in the HATs (averages are given in Table \ref{tab:branching}). In Figure \ref{fig:branching}, we plotted the branching factor against the number of nodes with this branching factor. The number of nodes is plotted on a logarithmic scale. The plot shows that HATs have far more binary expansions than dependency parses, but far less nodes that have 3-7 children. 

\begin{figure}[!ht]
\input{Graphics/branching.tex}
\caption{The branching factor plotted against the number of nodes with that branching factor on a logarithmic scale, for the 4 automatically aligned datasets.}\label{fig:branching}
\end{figure}


\section{Deeper Similarity of Alignments and Dependency Parses}
\label{sec:exp2}

In the second experiment, we measured the consistency of dependency parses and HAts through consistency definition \ref{def:depHAT2}. Once again, we ran the experiment on the first 10.000 sentences of our automatically aligned datasets and all manually aligned datasets, and reported on scores for sentences shorter than 10, 20 and 40 words. The results can be found in Table \ref{tab:scores1} and \ref{tab:scores2} (automatically and manually aligned, respectively).

The scores of the second experiment are much higher, which indicates that a large part of the previous low scores were indeed due to the mismatch of compositionality of HATs and dependency parses. However, the scores are still not as high as we would hope them to be (at most 0.85, for the manually aligned Hansard set).

%maybe change numbers to numbers of larger datasets later
\begin{table}[!ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
&\multicolumn{3}{c|}{\textbf{Similarity Score}}\\
\textbf{Language Pair} & |s| < 10 & |s| < 20 & |s| < 40\\
\hline \hline
English-Dutch & 0.79 & 0.74 & 0.71 \\
\hline
English-French & 0.80 & 0.77 & 0.76\\
\hline
English-German & 0.75 & 0.71 & 0.68 \\
\hline
English-Chinese & 0.76 & 0.67 & 0.62\\
\hline
\end{tabular}
\caption{Scores Experiment 2, automatic alignments}\label{tab:scores3}
\end{table}

\begin{table}[!ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
&\multicolumn{3}{c|}{\textbf{Similarity Score}}\\
\textbf{Language Pair} & |s| < 10 & |s| < 20 & |s| < 40\\
\hline \hline
English-French (Hansard) & 0.85 & 0.80 & 0.78 \\
\hline
English-French (LREC) & 0.78 & 0.82 & 0.82 \\
\hline
English-German (Pado) & 0.82 & 0.80 & 0.77 \\
\hline
English-Portuguese (LREC) & 0.75 & 0.76 & 0.76 \\
\hline
English- Spanish (LREC) & 0.79 & 0.80 & 0.80\\
\hline
\end{tabular}
\caption{Results Experiment 2, manual alignments}\label{tab:scores4}
\end{table}

We have created a plot of the distribution of the scores of the automatically aligned datasets. Except for the Chinese datasets, which will not further be discussed as the author has no knowledge of this language whatsoever, the maximal score is by far the most common score. Generally, there are few alignments that have a score just below the maximum score, which suggests that constructions do not prevent just one dependency from being preserved, but multiple at a time. The low number of sentences that have a very low score confirms the intuition that even sentences of which the dependency parses are not preserved are still for the larger part translated compositionally. In the next section, we will further investigate whether the lower scores can be explained by general phenomena, or are all individual cases. 

\begin{figure}[!ht]
\input{score_distribution.tex}
\caption{Distribution of the scores}\label{fig:scoredstrib}
\end{figure}

\section{Manual Analysis}
\label{sec:man}

We have conducted a manual analysis to gain more insight in the causes of inconsistency between dependency parses and HATs. We have restricted ourselves to an analysis of the manually aligned corpora, as their alignments will be more accurate. As the author of this paper masters neither Spanish nor Portuguese, the analysis is restrict to the language pairs English-German and English-French.

We randomly selected 100 sentences from the English-German dataset from \cite{pado2006optimal} and the English-French from \cite{graca2008building}.\footnote{Actually, the latter contained only 100 sentences, but lets say they were picked randomly} For every sentence, we determined whether the suboptimal score was due an error (in the dependency parse, the alignment or the translation), to severe rewording where a more literal translation was also available, or had another reason. In case there was an error in the data, we checked if the sentence would have received an optimal score if the error were corrected. In case of uncertainty a native speaker of the language was consulted. The results can be found in the following two subsections. We have plotted the score distribution for the two datasets, to confirm they show a pattern similar to the automatically aligned datasets.

\begin{figure}[!ht]
\input{score_distribution2.tex}
\caption{Distribution of the scores}\label{fig:scoredstrib2}
\end{figure}

\subsection{English-German}

The manually aligned datasets have on average more sentences that obtain  a maximal score. In the 100 sentences we selected from the manually aligned German-English corpus, 53 sentences have a score of 1.

In translation from German to English, we have found 3 main causes of dependency relations not being preserved during translation, besides errors in the data. We will discuss them in the following paragraphs. Table \ref{tab:optimal_score} summarises how often these cases occurred in the data, and what the average score of sentences classified in this class was.

\begin{table}[!ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Main Cause} & \textbf{\#sentences} & \textbf{Average} & \textbf{Average Corrected}\\
\hline \hline
Dependency Error & 8 & 0.60 & 0.84\\
\hline
Alignment Error & 2 & 0.69 & 1\\
\hline
Translation Error & 1 & 0.5 & 1\\
\hline
Literal & 5 & 0.52 & 1\\
\hline
phrasal& 9 & 0.57\\
\cline{1-3}
Max compositionality & 15 & 0.61 \\
\cline{1-3}
Different construction & 3 & 0.72 \\
\cline{1-3}
Other & 4 & 0.71\\
\cline{1-3}
\end{tabular}
\caption{Causes for non optimal scores}\label{tab:non_optimal}
\end{table}

\subsubsection{Maximal Compositionality}

As we have previously discussed, dependency parses are generally not maximally compositional. Although our scoring metrics allow to combine predicates and arguments to combine one by one, they do not allow arguments to combine together before they combine with their predicate. In translation from English to German, a language in which the word-order is relatively free, reordering of the arguments was a major cause of sentences being classified as not so compositional. 

Such cases were mainly caused by modifiers of verbs that occurred in a different place (such as `also'), verbs that split into two parts during translation, and hold all their arguments between their first and second part in German, or switching of arguments in a fashion that cannot be resolved by a binary tree. Some examples are given in the first Appendix, \ref{subsec:de_noncomp}.

\subsubsection{Phrasal Translations}

HATs account well for phrasal translations, and whenever a unit consisting of a predicate and one or more arguments consisting of just one word was translated phrasally, the dependency relations within were considered preserved. However, sometimes sequences of words that were phrasally translated did not constitute a unit according to the dependency parse, which caused at least two dependency relations not to be preserved. 

In translation from German to English, there were two cases in which phrasal translation beyond the dependency level occurred often. Firstly, when English auxiliary or linking verbs are translated to English, they are often translated together with another word that is not its head. For instance: `will be' is translated into `wird', `does not X', is translated into `nicht X', or `has been' is translated into `wurde'. In dependency parses auxiliary or linking verbs are rarely considered head of the sentence (e.g., in the sentence `he is a doctor', `doctor' will be marked head). If this linking verb is then translated phrasally together with another verb or word, this relation cannot be resolved (sometimes this can thus also be seen as a case of non maximal compositionality).

A second case for which phrasal translation beyond the dependency level occurs is in the translation of prepositions. Verbs that are accompanied by a preposition in English, are sometimes not accompanied by one in German. If the preposition is considered to be translated into the verb, this causes the dependency relation between the verb and the preposition to break down (and possibly all relations in the preposition). Examples are given in Appendix \ref{subsec:de_phrasal}

\subsubsection{Non literal translations}

In the German-English corpus, we have found some examples of translations whose structure deviated much from the original sentence, where a more literal alternative was also available. For instance, the translation of `Traffickers demand astronomical amounts to smuggle their customers to the West.' into `Die Haendler fordern von den Kunden, die sie in den Westen schmuggeln, astronomische Summen.'. The rewording in this sentence is quite severe, whereby the sentence is assigned a score of 0.4. However, the also perfectly grammatical and acceptable translation `Schmuggler verlangen astronomische Summen, um ihre Kunden in den Westen zu bringen', would receive an optimal score.


\subsubsection{Other}

Seven sentences, whose average score was 0.72, could not be grouped in one of the previously mentioned categories. In three of these cases, we judged the type of construction simply deviated so much during translation, that it was hard to account for compositionally. We will list these three examples:\begin{enumerate}
\item The translation of `I would like to see this question investigated' into `diese Frage muss meines Erachtens geklaert werden'.
\item The translation of `X would fail to find a buyer' into `X wurde keine abnehmer mehr finden'.
\item The translation of `The council received more than 100 questions' into `Es sind mehr als 100 Anfragen an den Rat gerichted worden'.
\end{enumerate} 

Of the resulting four translations, we found it hard to pinpoint what the exact reason was for the lower score. In two of these cases, a word earlier in the sentence was repeated later in one sentence, but not in its translation (`\textbf{I} think \textbf{I} can say' - `\textbf{Ich} glaube sage zu koennen', and (`\textbf{to} withdraw and stop' - `sich zuruck\textbf{zu}ziehen und schweigen \textbf{zu} lassen'). As the repeated word was aligned to both words in the other sentence, this caused the dependency structure to break. In the third sentence, the dependency parse did not seem to capture the structure of the sentence very well, but it was hard to fix without breaking the linear tree structure of the parse. In the fourth sentence, the English sentence seemed to be ambiguous, and the German sentence chose another meaning than the dependency parse.

\subsubsection{In conclusion}

In conclusion, we have seen that most of the lower scores were not due to non-compositionality. In Table \ref{tab:optimal_score} we see, that the majority of the sentences in the corpus obtained an optimal score, an additional 12 would have obtained an optimal score if the corpus were error free, or more literal (but acceptable) alternative translation were chosen, and 18 sentences did not receive a maximal score due to discrepancy of the type of compositionality of the HATs and the dependency parses. Furthermore, although not listed in the Table, it seems that phrasal translations beyond the dependency level should be accountable for in a compositional grammar, if some small adaptations on a general level were made.

\begin{table}[!ht]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Type} & \textbf{\#sentences}\\
\hline
\hline
Maximal score & 53 \\
\hline
Maximal score after correction error & 7\\
\hline
Literal alternative with maximal score & 5\\
\hline
Non compositionality due to maximality & 18\\
\hline
Total & 83\\
\hline
\end{tabular}
\caption{Compositionally translated sentences}\label{tab:optimal_score}
\end{table}

\subsection{French}

In the French-English corpus, reduction of the score due to different types of recursion was much less prevalent. Most of the low scores were due to severe rephrasing of the target sentence. In some cases, we judged that a more literal translation would have been just as acceptable (9 times), but in cases where only a couple words were freely translated, we counted it a a phrasal translation beyond the dependency level. There were very many of such phrasal translations, some of which captured general phenomena, which we will discuss.

\begin{table}[!ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Main Cause} & \textbf{\#sentences} & \textbf{Average} & \textbf{Average Corrected}\\
\hline \hline
Dependency Error & 12 & 0.57 & 0.96\\
\hline
Alignment Error & 2 & 0.75 & 1\\
\hline
Translation Error & 0 & 0 & 0 \\
\hline
Literal & 11 & 0.66  & 1\\
\hline
phrasal& 20 & 0.65 \\
\cline{1-3}
Max compositionality & 1 & 0.75\\
\cline{1-3}
Other & 3 & 0.42\\
\cline{1-3}
\end{tabular}
\caption{Reasons for non optimal scores}\label{tab:non_optimal2}
\end{table}

\subsubsection{Phrasal translation of negation}

In the previous chapter we have argued that HATs can account nicely for phrasal translation of negation. Dependency parses, however, do not. In dependency parses, a linking verb is never considered the head of the sentence, and negation of a sentence whose main verb is such a verb can thus not be resolved. We will illustrate this with a short example, examples from the data can be found in Appendix \ref{subsec:negation}. 

Consider the sentence `He is not happy' and its French translation `Il n'est pas content'. According to the dependency parse,  `content' is the head of the sentence, and `He', `not' and `happy' are all arguments of this predicate. However, `is not' is phrasally tranlsated into 'n'est pas', and both (`happy', `is') and (`happy', `not') will thus not be preserved during translation. However, this `non-compositionality' seems to be due to an unfortunate choice in the dependency parse, rather than to real non-compositionality.

\subsubsection{Phrasal translations of prepositions}

In French, prepositions are often contracted with the verb. For instance, the translation of `of the minutes', is `du process-verbal'. A dependency parse will see `of the minutes' as a prepositional phrase, of which `of' is the head. `the minutes' will be seen as the argument of `of'. However, when `of the' are phrasally translated into `du', both the relations (`of',`the minutes') and (`the',`minutes') will be considered not preserved.

\subsubsection{Other}

The three unclassified sentences were either not understandable for the author in the context, or of a too specific particular political jargon to be assessable.


\subsubsection{Conclusion}

In conclusion, we have seen that many of the scores were due to non literal translation. In addition, it seems that some of the design choice made in dependency parses, in particular the choice to not always make a verb the head of a sentence, are not particularly suitable for translation from English to French. Table \ref{tab:optimal_score2} shows how many sentences would have obtained a maximal score if the data were optimal for our purposes.

\begin{table}[!ht]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Type} & \textbf{\#sentences}\\
\hline
\hline
Maximal score & 51\\
\hline
Maximal score after correction error & 10 \\
\hline
Literal alternative with maximal score & 11 \\
\hline
Non compositionality due to maximality & 1 \\
\hline
Total & 73\\
\hline
\end{tabular}
\caption{description}\label{tab:optimal_score2}
\end{table}







\section{A more probabilistic Approach}
\label{sec:stat}

Explain how we have matched the two types of compositionality, was not completely consistent. To learn where it deviates, and what would best fit the entire corpus, we can \textit{learn} the grammar for the entire corpus, making use of dependency labels. By using dependency labels, the link with monolingual grammars stays in tact, but the learn algorithm can learn where to make adaptations, instead of always following dependency parses.


\section{}








%\bibliography{thesisDH}
%\end{document}