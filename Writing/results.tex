\documentclass[hidelinks]{report}
\input{commands.tex}

\begin{document}

\chapter{Experimental Results}

Introduction.

In this section we will report on our consistency results of the different corpora. The section consists of 5 parts:\begin{enumerate}
\item report datasets
\item discuss results direct similarity
\item discuss results deep similarity
\item discuss manual results
\item discuss EM results
\end{enumerate}


\section{Data}

\subsection{Corpora}

We had available 4 large automatically aligned parallel corpora for the language pairs English-Dutch, English-French, English-German and English-Chinese. The first thee corpora were data from the European Parliament taken from the Europarl corpus \citep{koehn2005europarl}, while the English-Chinese data came from the Hong Kong Parallel Corpus. The word-alignments were found using GIZA++ \citep{och03:asc}, using the previously mentioned `grow-diag-and-final'-heuristic, with 4 iterations on model 1, and 3 iterations with the hmm model, model 3 and model 4. The corpora were tokenised and lowercased before GIZA++ was run. In general, the guidelines for building a baseline for the WMT workshops were followed.\footnote{See http://www.statmt.org/wmt07/baseline.html}

In addition to the automatically aligned corpora, we had access to 5 (much smaller) manually aligned corpora, for the language pairs English-French, \citep{graca2008building,och2000improved} English-Spanish, English-Portuguese \citep{graca2008building}, English-German \citep{pado2006optimal}.

\begin{table}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\bf Language pair & \bf Source & \bf Size & \bf Alignments\\
\hline \hline
English - Dutch & European Parliament & 945167 & {\small GIZA++} \\
\hline
English - German & European Parliament & 995909 & {\small GIZA++} \\
& Europarl & 987 & {\small\cite{pado2006optimal}}\\
\hline
English - Chinese & Hong Kong Parallel Corpus & 1723487 & {\small GIZA++} \\
\hline
English - French & European Parliament & 949408 & {\small GIZA++} \\
& Hansard & 447 & {\small \cite{och2000improved}}\\
& Europarl & 100 & {\small \cite{graca2008building}} \\
\hline
English - Spanish & Europarl & 100 & {\small \cite{graca2008building}} \\
\hline
English - Portuguese & Europarl & 100 & {\small \cite{graca2008building}}\\
\hline
\end{tabular}
\caption{Datasets}\label{tab:datasets}
\end{table}

\subsection{Parses}

%Je hebt dit al gezegd, hoeft hier denk ik niet meer
The English side of the corpus was parsed with the Stanford dependency parser \citep{de2008stanford}, using new lines as delimitation to respect the sentence alignment of the corpora, to obtain basic typed dependencies of the sentence.  The set of dependencies considered by the parser does not include dependencies between words and punctuation (or punctuation and punctuation). More information on the different dependencies generated by the Stanford parser can be found in \cite{de2006generating}.

\section{Experiment part 1}

The first part of our experiment consisted of measuring the consistency of the corpus using definition \ref{def:depHAT}, as described before. The results for automatic and manual alignments can be found in Table \ref{tab:scores1} and \ref{tab:scores2}, respectively.

\begin{table}[!ht]
\begin{tabular}{|l|c|c|c|}
\hline
&\multicolumn{3}{c}{\textbf{Similarity Score}}\\
\textbf{Language Pair} & |s| < 10 & |s| < 20 & |s| < 40\\
\hline \hline
English-Dutch & 0.47 & 0.42 & 0.40 \\
\hline
English-French & 0.46 & 0.42 & 041 \\
\hline
English-German & 0.44 & 0.41 & 0.38 \\
\hline
English-Chinese & 0.59 & 0.48 & 0.42\\
\hline
\end{tabular}
\caption{Results experiment 1, automatic alignments}\label{tab:scores1}
\end{table}

\begin{table}[!ht]
\begin{tabular}{|l|c|c|c|}
\hline
&\multicolumn{3}{c}{\textbf{Similarity Score}}\\
\textbf{Language Pair} & |s| < 10 & |s| < 20 & |s| < 40\\
\hline \hline
English-French (Hansard) & 0.63 & 0.54 & 0.51 \\
English-French (LREC) & 0.49 & 0.47 & 0.47 \\
\hline
English-German (Pado) & 0.43 & 0.42 & 0.41 \\
\hline
English-Portuguese (LREC) & 0.47 & 0.45 & 0.45 \\
\hline
English- Spanish (LREC) & 0.51 & 0.48 & 0.48\\
\hline
\end{tabular}
\caption{Results Experiment 1, manual alignments}\label{tab:scores2}
\end{table}

As expected, the scores are quite low, because dependency parses are not maximally recursive. The influence of mistakes in the automatically aligned datasets seems relatively small, which might be attributed to the fact that manual alignments are generally more flat than automatic alignments \citep{simaan2013hats}, but can also be due to the small size of the manually aligned datasets. The large difference between the results for the two manually aligned french datasets seems to support the latter hypothesis.


%Also put nr of sentences in the table, + change to numbers of larger dataset
%Change tabel styles
%Hansard:{40: 148, 10: 97, 20: 202}
%LREC Frans {40: 0, 10: 29, 20: 71}
%LREC Portuguese {40: 0, 10: 29, 20: 71}
%LREC Spanish {40: 0, 10: 29, 20: 71}
%Pado {40: 632, 10: 63, 20: 275}




%\begin{figure}
%\input{score_distribution.tex}[!ht]
%\caption{Distribution of the scores}\label{fig:scoredstrib}
%\end{figure}


\section{Deeper Similarity of Alignments and Dependency Parses}

The scores obtained in Experiment, reported in Table \ref{tab:scores3} and \ref{tab:scores4}, are much better, showing that part of the low score found in Experiment 1 was in fact due to the discrepancy in the type of recursivity of HATs and dependency parses.


\begin{table}[!ht]
\begin{tabular}{|l|c|c|c|}
\hline
&\multicolumn{3}{c}{\textbf{Similarity Score}}\\
\textbf{Language Pair} & |s| < 10 & |s| < 20 & |s| < 40\\
\hline \hline
English-Dutch & 0.79 & 0.74 & 0.71 \\
\hline
English-French & 0.80 & 0.77 & 0.76\\
\hline
English-German & 0.75 & 0.71 & 0.68 \\
\hline
English-Chinese & 0.76 & 0.67 & 0.62\\
\hline
\end{tabular}
\caption{Scores Experiment 2, automatic alignments}\label{tab:scores3}
\end{table}

\begin{table}[!ht]
\begin{tabular}{|l|c|c|c|}
\hline
&\multicolumn{3}{c}{\textbf{Similarity Score}}\\
\textbf{Language Pair} & |s| < 10 & |s| < 20 & |s| < 40\\
\hline \hline
English-French (Hansard) & 0.85 & 0.80 & 0.78 \\
\hline
English-French (LREC) & 0.78 & 0.82 & 0.82 \\
\hline
English-German (Pado) & 0.82 & 0.80 & 0.77 \\
\hline
English-Portuguese (LREC) & 0.75 & 0.76 & 0.76 \\
\hline
English- Spanish (LREC) & 0.79 & 0.80 & 0.80\\
\hline
\end{tabular}
\caption{Results Experiment 2, manual alignments}\label{tab:scores4}
\end{table}



Briefly discuss some more reasons

\subsection{Reasons for deviation}

blablabla manual analysis of the manually aligned datasets. The only languages within this set known to the author of this paper are French and German... bla introduction

\subsubsection{German}

\subsubsection{Frans}

\subsubsection{Match up with rules?}

distribution of rules??

\section{A more probabilistic Approach}

Explain how we have matched the two types of compositionality, was not completely consistent. To learn where it deviates, and what would best fit the entire corpus, we can \textit{learn} the grammar for the entire corpus, making use of dependency labels. By using dependency labels, the link with monolingual grammars stays in tact, but the learn algorithm can learn where to make adaptations, instead of always following dependency parses.

Read of the grammar for entire corpus, parse entire corpus, read of grammar again


\section{}








\bibliography{thesisDH}
\end{document}